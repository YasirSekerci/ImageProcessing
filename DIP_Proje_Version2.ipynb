{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360d3e0-34d0-4643-aaa7-f07ee134d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b336f85-8fed-4e97-8329-3cef02b18bb5",
   "metadata": {},
   "source": [
    "# Kameradan Görüntü Alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d23c23-0469-4c2f-afc7-38e9120ff172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kameraya erişim sağlamak için VideoCapture objesini oluştur\n",
    "# 0, bilgisayarın varsayılan kamerasını ifade eder\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Kameraya erişilemiyor.\")\n",
    "    exit()\n",
    "\n",
    "# Döngü içinde görüntüyü sürekli olarak yakala ve ekrana göster\n",
    "#while True:\n",
    "    # Kameradan bir kare al\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Eğer görüntü başarıyla alınmadıysa döngüyü kır\n",
    "if not ret:\n",
    "    print(\"Görüntü alınamıyor.\")\n",
    "    #break\n",
    "    exit()\n",
    "\n",
    "# Görüntüyü ekrana yazdır\n",
    "\n",
    "cv2.imshow('Camera', frame)\n",
    "\n",
    "print(frame.shape)\n",
    "# 'q' tuşuna basıldığında döngüden çık\n",
    "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #break\n",
    "    exit()\n",
    "# İşlem bitince kamera ve pencereleri serbest bırak\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3a33d-a32f-4953-88f0-35497cc9b51d",
   "metadata": {},
   "source": [
    "# Gaussian ve Sobel Uygulama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45c0a8-05d9-4e61-92e4-0172d6536ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting BGR to RGB\n",
    "#frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "frame_red = frame[:, :, 2]\n",
    "frame_green = frame[:, :, 1]\n",
    "frame_blue = frame[:, :, 0]\n",
    "frame_rgb = np.dstack((frame_red, frame_green, frame_blue))\n",
    "\n",
    "plt.imshow(frame_rgb)\n",
    "plt.title(\"Frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf92d0-ab27-475b-b873-a2cb2acb2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(image):\n",
    "    height, width = image.shape[0:2]\n",
    "    grayscale_image = np.zeros((height, width), dtype=image.dtype)\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            red, green, blue = image[y][x]\n",
    "            gray = np.uint8(red * 0.299 + green * 0.5870 + blue * 0.1140)\n",
    "            grayscale_image[y][x] = gray\n",
    "            \n",
    "    return grayscale_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d701f-885e-4fc3-ba93-f94ec0af0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_grayscale = rgb_to_grayscale(frame)\n",
    "\n",
    "plt.imshow(frame_grayscale, cmap='gray')\n",
    "plt.title(\"Frame_grayscale\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70531abb-4c45-4139-a2ac-9a3ed8aa70cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b12566-f18c-43bd-95e8-0c8148ad854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(image, kernel_size = 3, sigma = 1):\n",
    "    sigma_squared = sigma ** 2\n",
    "    pi = math.pi\n",
    "    e_value = math.e\n",
    "    center = kernel_size // 2\n",
    "    gaussian_kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)\n",
    "\n",
    "    for y in range(-center, center + 1):\n",
    "        for x in range(-center, center + 1):\n",
    "            Gxy = (1 / (2 * pi * sigma_squared)) * (e_value ** ( -((x ** 2 + y ** 2) / (2 * sigma_squared))))\n",
    "            gaussian_kernel[y + center][x + center] = Gxy\n",
    "\n",
    "    \n",
    "    gaussian_kernel /= gaussian_kernel.sum()\n",
    "\n",
    "    height, width = image.shape\n",
    "    blurred_image = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    padded_image = np.zeros((height + center * 2, width + center * 2), dtype=np.uint8)\n",
    "\n",
    "    padded_image = np.pad(image, pad_width=center, mode='edge')\n",
    "#    for row in range(0, height + 2, 1):\n",
    "#        for column in range(0, width + 2, 1):\n",
    "#            if column == 0 and row == 0:\n",
    "#                padded_image[0][0] = image[0][0]\n",
    "#            elif (column == width + 1) and (row == height + 1):\n",
    "#                padded_image[row][column] = image[height - 1][width - 1]\n",
    "#            elif (column == width + 1) and row == 0:\n",
    "#                padded_image[0][column] = image[0][width - 1]\n",
    "#            elif column == 0 and (row == height + 1):\n",
    "#                padded_image[row][0] = image[height - 1][0]\n",
    "#            elif row == 0:\n",
    "#                padded_image[0][column] = image[0][column - 1]\n",
    "#            elif column == 0:\n",
    "#                padded_image[row][0] = image[row - 1][0]\n",
    "#            elif row == height + 1:\n",
    "#                padded_image[row][column] = image[row - 2][column - 1]\n",
    "#            elif column == width + 1:\n",
    "#                padded_image[row][column] = image[row - 1][column - 2]\n",
    "#            else:\n",
    "#                padded_image[row][column] = image[row - 1][column - 1]    \n",
    "\n",
    "    for row in range(1, height + 1, 1):\n",
    "        for column in range(1, width + 1, 1):\n",
    "            total = 0\n",
    "            for y in range(kernel_size):\n",
    "                for x in range(kernel_size):\n",
    "                    total += gaussian_kernel[y][x] * padded_image[row + y - 1][column + x - 1]\n",
    "\n",
    "            blurred_image[row - 1][column - 1] = np.clip(round(total), 0, 255)\n",
    "\n",
    "    print(blurred_image)\n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862af372-b7e1-4549-9bde-d3663ce34041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_grayscale_frame = gaussian_filter(frame_grayscale, kernel_size = 7, sigma = 1)\n",
    "\n",
    "plt.imshow(filtered_grayscale_frame, cmap='gray')\n",
    "plt.title(\"filtered_grayscale_frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58cfc3-6918-45ca-bebb-6ad3670489aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_filter(image):\n",
    "    sobel_filter_x = np.array([[-1, 0, 1],\n",
    "                               [-2, 0, 2],\n",
    "                               [-1, 0, 1]])\n",
    "    sobel_filter_y = np.array([[-1, -2, -1],\n",
    "                               [0, 0, 0],\n",
    "                               [1, 2, 1]])\n",
    "    kernel_size = 3\n",
    "    \n",
    "    height, width = image.shape\n",
    "    filtered_image = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    padded_image = np.zeros((height + 2, width + 2), dtype=np.uint8)\n",
    "    magnitudes = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    padded_image = np.pad(image, pad_width=1, mode='edge')\n",
    "#    for row in range(0, height + 2, 1):\n",
    "#        for column in range(0, width + 2, 1):\n",
    "#            if column == 0 and row == 0:\n",
    "#                padded_image[0][0] = image[0][0]\n",
    "#            elif (column == width + 1) and (row == height + 1):\n",
    "#                padded_image[row][column] = image[height - 1][width - 1]\n",
    "#            elif (column == width + 1) and row == 0:\n",
    "#                padded_image[0][column] = image[0][width - 1]\n",
    "#            elif column == 0 and (row == height + 1):\n",
    "#               padded_image[row][0] = image[height - 1][0]\n",
    "#            elif row == 0:\n",
    "#                padded_image[0][column] = image[0][column - 1]\n",
    "#            elif column == 0:\n",
    "#                padded_image[row][0] = image[row - 1][0]\n",
    "#            elif row == height + 1:\n",
    "#                padded_image[row][column] = image[row - 2][column - 1]\n",
    "#            elif column == width + 1:\n",
    "#                padded_image[row][column] = image[row - 1][column - 2]\n",
    "#            else:\n",
    "#                padded_image[row][column] = image[row - 1][column - 1]    \n",
    "\n",
    "    for row in range(1, height + 1, 1):\n",
    "        for column in range(1, width + 1, 1):\n",
    "            total_x = 0\n",
    "            total_y = 0\n",
    "            for y in range(kernel_size):\n",
    "                for x in range(kernel_size):\n",
    "                    total_x += sobel_filter_x[y][x] * padded_image[row + y - 1][column + x - 1]\n",
    "                    total_y += sobel_filter_y[y][x] * padded_image[row + y - 1][column + x - 1]\n",
    "            magnitude = np.sqrt(total_x**2 + total_y**2)\n",
    "            magnitudes[row - 1][column - 1] = magnitude\n",
    "\n",
    "    threshold = 40   \n",
    "    min_magnitude = magnitudes.min()\n",
    "    max_magnitude = magnitudes.max()\n",
    "\n",
    "    if max_magnitude - min_magnitude > 0:\n",
    "        normalized_magnitudes = (magnitudes - min_magnitude) / (max_magnitude - min_magnitude) * 255\n",
    "        filtered_image = np.where(normalized_magnitudes > threshold, normalized_magnitudes, 0).astype(np.uint8)\n",
    "    else:\n",
    "        filtered_image = np.zeros_like(magnitudes, dtype=np.uint8)\n",
    "\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b680e4-e077-4ab8-9ccf-225956db72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dedection_grayscale_frame = sobel_filter(filtered_grayscale_frame)\n",
    "\n",
    "plt.imshow(edge_dedection_grayscale_frame, cmap='gray')\n",
    "plt.title(\"edge_dedection_grayscale_frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d2253-470d-4f2d-9a98-7c2ca745a6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3644f0f0-dd65-4baa-a985-3c6e86d225c8",
   "metadata": {},
   "source": [
    "# Geometrik İlişkilere Dayalı Yüz Algılama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb79f2b-c0a0-4e34-987e-f073257a9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findContours(binary_image):\n",
    "#    height, width = binary_image.shape\n",
    "#    white_pixels = []\n",
    "\n",
    "#    for y in range(height):\n",
    "#        for x in range(width):\n",
    "#            if binary_image[y, x] == 255:\n",
    "#                white_pixels.append((x, y))\n",
    "\n",
    "    height, width = binary_image.shape\n",
    "    visited = np.zeros((height, width), dtype=bool)\n",
    "    contours = []\n",
    "\n",
    "    def DFS(x, y, current_contour):\n",
    "        if x < 0 or y < 0 or x >= width or y >= height:\n",
    "            return\n",
    "\n",
    "        if visited[y, x] or binary_image[y, x] == 0:\n",
    "            return\n",
    "\n",
    "        visited[y, x] = True\n",
    "        current_contour.append((x, y))\n",
    "\n",
    "        for Nx, Ny in [(-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1), (0, 1), (-1, 1)]:\n",
    "            DFS(x + Nx, y + Ny, current_contour)\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if binary_image[y, x] == 255 and not visited[y, x]:\n",
    "                current_contour = []\n",
    "                DFS(x, y, current_contour)\n",
    "\n",
    "                if current_contour:\n",
    "                    contours.append(current_contour)\n",
    "    return contours\n",
    "    \n",
    "    compresed_contours = []\n",
    "    for contour in contours:\n",
    "        compresed_contour = []\n",
    "        previous_direction = None\n",
    "    \n",
    "        for i in range(len(contour)):\n",
    "            dx = contour[i][0] - contour[i - 1][0]\n",
    "            dy = contour[i][1] - contour[i - 1][1]\n",
    "            direction = (dx, dy)\n",
    "\n",
    "            if direction != previous_direction:\n",
    "                compresed_contour.append(contour[i-1])\n",
    "                previous_direction = direction\n",
    "\n",
    "        compresed_contour.append(contour[-1])\n",
    "        compresed_contours.append(compresed_contour)\n",
    "\n",
    "    def calculate_bounding_box(contour):\n",
    "        x_min = min(point[0] for point in contour)\n",
    "        x_max = max(point[0] for point in contour)\n",
    "        y_min = min(point[1] for point in contour)\n",
    "        y_max = max(point[1] for point in contour)\n",
    "        return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    def is_inside(inner_box, outer_box):\n",
    "        inner_x_min, inner_y_min, inner_x_max, inner_y_max = inner_box\n",
    "        outer_x_min, outer_y_min, outer_x_max, outer_y_max = outer_box\n",
    "        return (inner_x_min > outer_x_min and inner_y_min > outer_y_min and inner_x_max < outer_x_max and inner_y_max < outer_y_max)\n",
    "\n",
    "    def calculate_area(contour):\n",
    "        n = len(contour)\n",
    "        area = 0\n",
    "        for i in range(n):\n",
    "            x1, y1 = contour[i]\n",
    "            x2, y2 = contour[(i + 1) % n]\n",
    "            area += x1 * y2 - y1 * x2\n",
    "        return abs(area) / 2\n",
    "\n",
    "    def sort_contours(contours):\n",
    "        areas = []\n",
    "        for index, contour in enumerate(contours):\n",
    "            area = calculate_area(contour)\n",
    "            areas.append((index, area))\n",
    "\n",
    "        sorted_areas = sorted(areas, key=lambda item: item[1], reverse=false)\n",
    "\n",
    "        sorted_contours =  []\n",
    "        for item in sorted_areas:\n",
    "            contour_index = item[0]\n",
    "            sorted_contours.append(contours[contour_index])\n",
    "\n",
    "        return sorted_contours\n",
    "\n",
    "\n",
    "    def calculate_hierarchy(contours):\n",
    "        sorted_contours = sort_contours(contours)\n",
    "        bounding_boxes = [calculate_bounding_box(contour) for contour in sorted_contours]\n",
    "        hierarchy = [{\"parent\": -1, \"children\": []} for _ in sorted_contours]\n",
    "\n",
    "        for i, inner_box in enumerate(bounding_boxes):\n",
    "            for j, outer_box in enumerate(bounding_boxes):\n",
    "                if i != j and is_inside(inner_box, outer_box):\n",
    "                    if hierarchy[i][\"parent\"] == -1:\n",
    "                        hierarchy[i][\"parent\"] = j\n",
    "                        hierarchy[j][\"children\"].append(i)\n",
    "    \n",
    "        return sorted_contours, hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3798ae-5264-4297-aa7f-b53b1804e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingRect(contour):\n",
    "    x_coords = [point[0] for point in contour]\n",
    "    y_coords = [point[1] for point in contour]\n",
    "\n",
    "    x_min = min(x_coords)\n",
    "    x_max = max(x_coords)\n",
    "    y_min = min(y_coords)\n",
    "    y_max = max(y_coords)\n",
    "\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "\n",
    "    print(x_min, x_max, y_min, y_max, width, height)\n",
    "\n",
    "    return x_min, y_min, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e520f6e-90f9-44e7-9b82-434b1747a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eyes(top_half):\n",
    "    threshold = 50\n",
    "    # Pixel değeri threshold'dan büyükse pixel'i 255, küçükse 0 yapar.\n",
    "    binary_top = np.where(top_half > threshold, 255, 0).astype(np.uint8)\n",
    "\n",
    "    # Gözlerin olabileceği yuvarlak bölgeleri bul\n",
    "#    contours, _ = cv2.findContours(binary_top, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = findContours(binary_top)\n",
    "    eyes = []\n",
    "    for contour in contours:\n",
    "        print(\"****\"*10)\n",
    "        print(contour)\n",
    "        print(\"****\"*10)\n",
    "        x, y, w, h = boundingRect(contour)\n",
    "        if 10 < w < 150 and 10 < h < 150:  # Göz boyutları için mantıklı bir aralık\n",
    "            aspect_ratio = w / h \n",
    "            eyes.append((x, y, w, h))\n",
    "    return eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fd20b-bf77-4bb8-9a46-ef463b9548a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Bounding box hesaplama\n",
    "def calculate_bounding_box(contour):\n",
    "    x_min = min(point[0] for point in contour)\n",
    "    x_max = max(point[0] for point in contour)\n",
    "    y_min = min(point[1] for point in contour)\n",
    "    y_max = max(point[1] for point in contour)\n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "# İç içe kontrolü\n",
    "def is_inside(inner, outer):\n",
    "    inner_x_min, inner_y_min, inner_x_max, inner_y_max = inner\n",
    "    outer_x_min, outer_y_min, outer_x_max, outer_y_max = outer\n",
    "    return (inner_x_min > outer_x_min and inner_y_min > outer_y_min and\n",
    "            inner_x_max < outer_x_max and inner_y_max < outer_y_max)\n",
    "\n",
    "\n",
    "def calculate_area(contour):\n",
    "    \"\"\"\n",
    "    Shoelace algoritmasını kullanarak verilen bir konturun alanını hesaplar.\n",
    "    \"\"\"\n",
    "    n = len(contour)\n",
    "    area = 0\n",
    "    for i in range(n):\n",
    "        x1, y1 = contour[i]\n",
    "        x2, y2 = contour[(i + 1) % n]  # Bir sonraki nokta (son nokta için ilk noktaya döner)\n",
    "        area += x1 * y2 - y1 * x2\n",
    "    return abs(area) / 2  # Alanın mutlak değeri\n",
    "\n",
    "def sort_contours_by_area(contours):\n",
    "    \"\"\"\n",
    "    Konturları kapladıkları alana göre büyükten küçüğe sıralar.\n",
    "    \"\"\"\n",
    "    areas = [(i, calculate_area(contour)) for i, contour in enumerate(contours)]\n",
    "    # Alanlara göre sıralama (büyükten küçüğe)\n",
    "    sorted_areas = sorted(areas, key=lambda x: x[1], reverse=False)\n",
    "    # Sıralanmış konturların indekslerini döndür\n",
    "    return [contours[i[0]] for i in sorted_areas]\n",
    "\n",
    "\n",
    "# Hiyerarşi hesaplama\n",
    "def calculate_hierarchy(contours):\n",
    "    contours = sort_contours_by_area(contours)\n",
    "    bounding_boxes = [calculate_bounding_box(contour) for contour in contours]\n",
    "    hierarchy = [{\"parent\": -1, \"children\": []} for _ in contours]\n",
    "    # Parent ve child ilişkilerini belirleme\n",
    "    for i, inner_box in enumerate(bounding_boxes):\n",
    "        for j, outer_box in enumerate(bounding_boxes):\n",
    "            if i != j and is_inside(inner_box, outer_box):\n",
    "                # Eğer `i`, `j`'nin parent'ıysa\n",
    "                if hierarchy[i][\"parent\"] == -1:  # Zaten bir parent atanmadıysa\n",
    "                    hierarchy[i][\"parent\"] = j\n",
    "                    hierarchy[j][\"children\"].append(i)\n",
    "\n",
    "    return hierarchy\n",
    "\n",
    "# Örnek konturlar\n",
    "contours = [\n",
    "    [(1, 1), (1, 4), (4, 4), (4, 1)],   # Kontur 0: Dış kontur\n",
    "    [(2.2, 2.2), (2.2, 2.5), (2.5, 2.5), (2.5, 2.2)],  # Kontur 1: Kontur 3'in içinde\n",
    "    [(5, 5), (5, 7), (7, 7), (7, 5)],   # Kontur 2: Bağımsız\n",
    "    [(2, 2), (2, 3), (3, 3), (3, 2)],    # Kontur 3: Kontur 0'ın içinde\n",
    "    [(3.2, 1.5), (3.2, 1.8), (3.5, 1.8), (3.5, 1.5)]   # Kontur 4: Kontur 0'ın içinde, Kontur 3'ten bağımsız\n",
    "]\n",
    "\n",
    "hierarchy = calculate_hierarchy(contours)\n",
    "\n",
    "# Hiyerarşi yazdırma\n",
    "for i, relation in enumerate(hierarchy):\n",
    "    print(f\"Kontur {i}:\")\n",
    "    print(f\"  Ebeveyn: {relation['parent']}\")\n",
    "    print(f\"  Çocuklar: {relation['children']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b49c4-a576-416b-9626-fd7509b8d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntüyü 2'ye bölme. Bunu yapma amacımız yukarıdaki görüntüde gözleri, alttaki görüntüde burun ve ağzı bulmak.\n",
    "height, width = edge_dedection_grayscale_frame.shape\n",
    "top_half = edge_dedection_grayscale_frame[:height // 2, :]\n",
    "top_half1 = edge_dedection_grayscale_frame[:height // 2, :]\n",
    "bottom_half = edge_dedection_grayscale_frame[height // 2: , :]\n",
    "\n",
    "plt.imshow(top_half, cmap=\"gray\")\n",
    "plt.title(\"top_half\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(bottom_half, cmap=\"gray\")\n",
    "plt.title(\"bottom_half\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbaed8-ab15-42b0-b634-22ae697afe2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gözlerin yerini bul\n",
    "eye_regions = find_eyes(top_half)\n",
    "for (x, y, w, h) in eye_regions:\n",
    "#    print(\"**********************\"*10)\n",
    "#    print(x, y, w, h)\n",
    "#    print(\"**********************\"*10)\n",
    "    cv2.rectangle(top_half, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "plt.imshow(top_half, cmap='gray')\n",
    "plt.title(\"Gözlerin Yerleri\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb0566-2110-4a88-bca4-e1dd44206c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eyes(top_half):\n",
    "    # Yoğun kontrastlı bölgeleri belirlemek için bir eşik belirleyin\n",
    "    threshold = 50\n",
    "    binary_top = np.where(top_half > threshold, 255, 0).astype(np.uint8)\n",
    "\n",
    "    # Gözlerin olabileceği yuvarlak bölgeleri bul\n",
    "    contours, _ = cv2.findContours(binary_top, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    eyes = []\n",
    "    for contour in contours:\n",
    "        # Göz boyutuna uygun konturlar seç\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if 10 < w < 50 and 10 < h < 50:  # Göz boyutları için mantıklı bir aralık\n",
    "            eyes.append((x, y, w, h))\n",
    "    return eyes\n",
    "\n",
    "# Gözlerin yerini bul\n",
    "eye_regions = find_eyes(top_half)\n",
    "for (x, y, w, h) in eye_regions:\n",
    "    cv2.rectangle(top_half, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "plt.imshow(top_half, cmap='gray')\n",
    "plt.title(\"Gözlerin Yerleri\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25ba88-5aee-49e7-81f7-963d571c1a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62b666-73bc-4213-a4d5-0047ee8be563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eyes1(top_half):\n",
    "    threshold = 50\n",
    "    # Pixel değeri threshold'dan büyükse pixel'i 255, küçükse 0 yapar.\n",
    "    binary_top = np.where(top_half > threshold, 255, 0).astype(np.uint8)\n",
    "\n",
    "    # Gözlerin olabileceği yuvarlak bölgeleri bul\n",
    "    contours, _ = cv2.findContours(binary_top, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#    contours = findContours(binary_top)\n",
    "    eyes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if 10 < w < 50 and 10 < h < 50:  # Göz boyutları için mantıklı bir aralık\n",
    "            eyes.append((x, y, w, h))\n",
    "    return eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801da25-b4e1-4e77-9197-0c00bf67e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gözlerin yerini bul\n",
    "eye_regions = find_eyes1(top_half1)\n",
    "for (x, y, w, h) in eye_regions:\n",
    "    cv2.rectangle(top_half, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "plt.imshow(top_half, cmap='gray')\n",
    "plt.title(\"Gözlerin Yerleri\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8502c-8d49-466f-9ec5-66ce0ae7176e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570ff98-2bc6-4b12-9dae-f183d7eef49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9169736-46de-484a-9823-05a4e6432988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34adec9f-677c-4954-bd26-d4fe56b7a785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bb0e5ce-d845-4f5c-bd55-0962e1cd49cd",
   "metadata": {},
   "source": [
    "# Şablon Eşleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbff732-b377-4681-99cd-4b54c3363efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "template_image = cv2.imread(\"./face.jpg\")\n",
    "\n",
    "frame_red = template_image[:, :, 2]\n",
    "frame_green = template_image[:, :, 1]\n",
    "frame_blue = template_image[:, :, 0]\n",
    "frame_rgb = np.dstack((frame_red, frame_green, frame_blue))\n",
    "\n",
    "plt.imshow(frame_rgb)\n",
    "plt.title(\"Frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df83fe-e332-4e2a-91a2-74d5fc165b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_image_grayscale = rgb_to_grayscale(frame_rgb)\n",
    "\n",
    "plt.imshow(template_image_grayscale, cmap='gray')\n",
    "plt.title(\"Frame_grayscale\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9ada4-061b-45e6-af6a-f5f965a1d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_template_image = gaussian_filter(template_image_grayscale, kernel_size = 7, sigma = 0.7)\n",
    "\n",
    "plt.imshow(filtered_template_image, cmap='gray')\n",
    "plt.title(\"filtered_grayscale_frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640baf5c-45d8-420b-8916-954ec9ca14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dedection_template_image = sobel_filter(filtered_template_image)\n",
    "\n",
    "plt.imshow(edge_dedection_template_image, cmap='gray')\n",
    "plt.title(\"edge_dedection_grayscale_frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e6a4b-63d0-4a6b-9195-e786cf4b1050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_eye = edge_dedection_template_image[50:100, 180:220]\n",
    "right_eye = edge_dedection_template_image[50:100, 240:280]\n",
    "nose = edge_dedection_template_image[80:120, 210:250]\n",
    "mouth = edge_dedection_template_image[125:150, 200:260]\n",
    "left_eye = np.where(left_eye > 50, left_eye, 0)\n",
    "plt.imshow(left_eye, cmap='gray')\n",
    "plt.title(\"left_eye\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(right_eye, cmap='gray')\n",
    "plt.title(\"right_eye\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(nose, cmap='gray')\n",
    "plt.title(\"nose\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mouth, cmap='gray')\n",
    "plt.title(\"mouth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0549999-72c8-4bd1-bab2-837655340034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching(image, template):\n",
    "    i_height, i_width = image.shape\n",
    "    t_height, t_width = template.shape\n",
    "    result = np.zeros((i_height - t_height + 1, i_width - t_width + 1))\n",
    "    \n",
    "    for y in range(i_height - t_height + 1):\n",
    "        for x in range(i_width - t_width + 1):\n",
    "            region = image[y:y+t_height, x:x+t_width]\n",
    "            print(\"y=\", y, \"x=\", x)\n",
    "            plt.imshow(region, cmap = \"gray\")\n",
    "            plt.show()\n",
    "            result[y, x] = np.sum(np.abs(region - template))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e7fd4-e8ae-4c93-b5c5-288a49dce3a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deneme = edge_dedection_grayscale_frame[220:250, 230:275]\n",
    "plt.imshow(deneme, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "deneme2 = left_eye[15:33, :]\n",
    "plt.imshow(deneme2, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "i_height, i_width = deneme.shape\n",
    "t_height, t_width = deneme2.shape\n",
    "resized_image = cv2.resize(deneme, (t_width, t_height))\n",
    "plt.imshow(resized_image, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "def normalized_cross_correlation(image1, image2):\n",
    "    # Normalize etmek için piksel değerlerini ortalama ve standart sapmaya göre merkezle\n",
    "    image1_mean = np.mean(image1)\n",
    "    image2_mean = np.mean(image2)\n",
    "    image1_std = np.std(image1)\n",
    "    image2_std = np.std(image2)\n",
    "\n",
    "    # Normalize edilmiş görüntüleri oluştur\n",
    "    image1_normalized = (image1 - image1_mean) / image1_std\n",
    "    image2_normalized = (image2 - image2_mean) / image2_std\n",
    "\n",
    "    # NCC değerini hesapla\n",
    "    ncc_value = np.sum(image1_normalized * image2_normalized)\n",
    "    ncc_value /= image1.shape[0] * image1.shape[1]  # Ortalama değer\n",
    "\n",
    "    return ncc_value\n",
    "\n",
    "# NCC değerini hesapla\n",
    "ncc = normalized_cross_correlation(resized_image, deneme2)\n",
    "\n",
    "# NCC değerini yüzdelik forma çevir\n",
    "similarity = ncc * 100  # NCC -1 ile 1 arasında olduğundan, % olarak ifade etmek için 100 ile çarpıyoruz\n",
    "\n",
    "print(f\"Görsellerin NCC ile benzeme oranı: {similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b37d18-6eec-4cfc-b08b-466d4d799e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_left_eye = template_matching(edge_dedection_grayscale_frame, left_eye)\n",
    "result_right_eye = template_matching(edge_dedection_grayscale_frame, right_eye)\n",
    "result_nose = template_matching(edge_dedection_grayscale_frame, nose)\n",
    "result_mouth = template_matching(edge_dedection_grayscale_frame, mouth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc41c9-4fb2-4ebb-a7c7-6badcc6440e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol göz için en düşük SAD değerini bul\n",
    "min_val, _, min_loc, _ = cv2.minMaxLoc(result_left_eye)\n",
    "left_eye_location = min_loc  # (x, y) formatında en iyi eşleşme koordinatı\n",
    "\n",
    "right_eye_location = cv2.minMaxLoc(result_right_eye)[2]\n",
    "nose_location = cv2.minMaxLoc(result_nose)[2]\n",
    "mouth_location = cv2.minMaxLoc(result_mouth)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de808b2-6b6a-4d6d-8500-6681001e3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol göz için bir dikdörtgen çiz\n",
    "x, y = left_eye_location\n",
    "cv2.rectangle(edge_dedection_grayscale_frame, (x, y), (x+left_eye.shape[1], y+left_eye.shape[0]), (255, 0, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c3f3d-5614-4da7-b43d-fffd0211ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(edge_dedection_grayscale_frame, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2012462-4ede-4a5e-be34-88b6b8308863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cb8d1-525e-4a64-948e-985357279053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695d593-a02e-40d2-ad55-d2b450e983a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228969a-0ae3-4c71-8ac7-52280c16b429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e86a46-d9a6-4516-b3b3-74fab1ef606e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740de49-b25a-452e-a927-c3adc7b62107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb4fb6-68b3-4ba2-845b-9f9fda16d313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e8b5d-a429-435c-8c23-558335090ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707d880-4714-459c-8c67-fb6b554c5e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917afd7-f7ba-46f4-9bc9-72ceba7d83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_components(binary_image):\n",
    "    height, width = binary_image.shape\n",
    "\n",
    "    labels = np.zeros((height, width), dtype=np.int32)\n",
    "    current_label = 1\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if binary_image[y][x] == 255 and labels[y][x] == 0:\n",
    "                stack = [(y, x)]\n",
    "                labels[y][x] = current_label\n",
    "\n",
    "                while stack:\n",
    "                    cy, cx = stack.pop()\n",
    "\n",
    "                    for ny in range(cy - 1, cy + 2):\n",
    "                        for nx in range(cx - 1, cx + 2):\n",
    "                            if (0 <= ny < height) and (0 <= nx < width) and (binary_image[ny][nx] == 255) and (labels[ny][nx] == 0):\n",
    "                                labels[ny][nx] = current_label\n",
    "                                stack.append((ny, nx))\n",
    "\n",
    "                current_label += 1\n",
    "\n",
    "    return labels, current_label - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e0d85-4d70-41b4-aff9-09c14f085191",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image = (edge_dedection_grayscale_frame > 0).astype(np.uint8) * 255\n",
    "\n",
    "plt.imshow(binary_image)\n",
    "plt.title(\"binary_image\")\n",
    "plt.show()\n",
    "\n",
    "labels, num_components = connected_components(binary_image)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(binary_image, cmap='gray')\n",
    "ax.set_title(\"Yüz Olabilecek Bölgeler\")\n",
    "for label in range(1, num_components + 1):\n",
    "    # Bu bileşene ait piksellerin koordinatlarını bulun\n",
    "    component_pixels = np.where(labels == label)\n",
    "    \n",
    "    # Dikdörtgenin sol üst ve sağ alt köşelerini belirleyin\n",
    "    y_min, y_max = np.min(component_pixels[0]), np.max(component_pixels[0])\n",
    "    x_min, x_max = np.min(component_pixels[1]), np.max(component_pixels[1])\n",
    "    \n",
    "    min_size = 100\n",
    "    max_size = 500\n",
    "    if min_size <= (x_max - x_min) <= max_size and min_size <= (y_max - y_min) <= max_size:\n",
    "        # En-boy oranı filtresi\n",
    "#        aspect_ratio = (x_max - x_min) / (y_max - y_min)\n",
    "#        if 0.8 <= aspect_ratio <= 1.2:\n",
    "            # Kenar yoğunluğu filtresi\n",
    "            component_area = (y_max - y_min) * (x_max - x_min)\n",
    "            edge_density = np.sum(labels[y_min:y_max+1, x_min:x_max+1] == label) / component_area\n",
    "            if edge_density > 0.3:  # Kenar yoğunluğu yeterliyse yüz olarak kabul et\n",
    "                # Yüz olma ihtimali yüksek bölgeye dikdörtgen çiz\n",
    "                rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
    "                                     edgecolor='red', facecolor='none', linewidth=2)\n",
    "                ax.add_patch(rect)\n",
    "                print(f\"Bölge {label} dikdörtgen olarak işaretlendi.\")\n",
    "                print(x_max, x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7e8d2-4bb9-4f7d-928c-dc35150355b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e558d-0bae-48a5-94a7-61f62e45d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19b406-7931-4dfb-95d5-a190edeb4582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c7cea-2c37-44e6-ae1b-e46a0cb75886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, window_size, step_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1], step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0], step_size):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "def multi_scale_face_detection(edge_image, initial_window_size=(150, 150), scale_factor=0.9, min_window_size=(50, 50), edge_threshold=1000):\n",
    "    best_region = None\n",
    "    best_edge_count = 0\n",
    "    current_image = edge_image.copy()\n",
    "    current_window_size = initial_window_size\n",
    "\n",
    "    while current_image.shape[0] >= min_window_size[1] and current_image.shape[1] >= min_window_size[0]:\n",
    "        # Kaydırmalı pencereyi mevcut ölçekte uygula\n",
    "        for (x, y, window) in sliding_window(current_image, current_window_size, step_size=10):\n",
    "            edge_count = np.sum(window)  # Kenar yoğunluğunu hesapla\n",
    "            \n",
    "            if edge_count > edge_threshold and edge_count > best_edge_count:\n",
    "                best_edge_count = edge_count\n",
    "                best_region = (x, y, current_window_size[0], current_window_size[1])\n",
    "\n",
    "        # Görüntüyü yeniden boyutlandır (ölçeği küçült)\n",
    "        current_image = current_image[::int(1/scale_factor), ::int(1/scale_factor)]\n",
    "        current_window_size = (int(current_window_size[0] * scale_factor), int(current_window_size[1] * scale_factor))\n",
    "\n",
    "    return best_region\n",
    "\n",
    "\n",
    "\n",
    "def find_face_region(edge_image, window_size=(250, 250), step_size=10, edge_threshold=1000):\n",
    "    best_region = None\n",
    "    best_edge_count = 0\n",
    "\n",
    "    for (x, y, window) in sliding_window(edge_image, window_size, step_size):\n",
    "        edge_count = np.sum(window)  # Kenar yoğunluğunu hesapla\n",
    "\n",
    "        if edge_count > edge_threshold and edge_count > best_edge_count:\n",
    "            best_edge_count = edge_count\n",
    "            best_region = (x, y, window_size[0], window_size[1])\n",
    "\n",
    "    return best_region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfa95a-cbdf-46a3-9540-fa5658afb3fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_face_box(image, face_regions):\n",
    "    for face_region in face_regions:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        if face_region:\n",
    "            x, y, w, h = face_region\n",
    "            rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "a = multi_scale_face_detection(edge_dedection_grayscale_frame)\n",
    "draw_face_box(edge_dedection_grayscale_frame, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d4016-c8f2-41a9-be36-c98cc57068ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "eye_image = cv.imread('face.jpg', cv.IMREAD_COLOR)\n",
    "#image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "frame_red = eye_image[:, :, 2]\n",
    "frame_green = eye_image[:, :, 1]\n",
    "frame_blue = eye_image[:, :, 0]\n",
    "eye_rgb = np.dstack((frame_red, frame_green, frame_blue))\n",
    "\n",
    "plt.imshow(eye_rgb)\n",
    "plt.title(\"Frame\")\n",
    "plt.show()\n",
    "\n",
    "eye_grayscale = rgb_to_grayscale(eye_rgb)\n",
    "\n",
    "plt.imshow(eye_grayscale)\n",
    "plt.title(\"Frame_grayscale\")\n",
    "plt.show()\n",
    "\n",
    "filtered_eye = gaussian_filter(eye_grayscale, kernel_size = 3, sigma = 5)\n",
    "\n",
    "plt.imshow(filtered_eye)\n",
    "plt.title(\"filtered_grayscale_frame\")\n",
    "plt.show()\n",
    "\n",
    "edge_dedection_eye = sobel_filter(filtered_eye)\n",
    "\n",
    "plt.imshow(edge_dedection_eye)\n",
    "plt.title(\"edge_dedection_grayscale_frame\")\n",
    "plt.show()\n",
    "\n",
    "edge_dedection_eye_scale = edge_dedection_eye[140:180, 210:280]\n",
    "\n",
    "plt.imshow(edge_dedection_eye_scale)\n",
    "plt.title(\"edge_dedection_eye_scale\")\n",
    "plt.show()\n",
    "#deneme = list([0, 0, original_image_rgb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157eeca-88df-41c4-82fb-a7727039c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def template_matching(image, template, step_size=10):\n",
    "    h, w = template.shape  # Şablon boyutları\n",
    "    img_h, img_w = image.shape  # Ana görüntü boyutları\n",
    "    \n",
    "    best_match = None\n",
    "    best_score = float('inf')  # En düşük farkı arıyoruz\n",
    "    \n",
    "    # Kaydırmalı pencere işlemi\n",
    "    for y in range(0, img_h - h, step_size):\n",
    "        for x in range(0, img_w - w, step_size):\n",
    "            # Şablonun ana görüntüdeki bu bölgeyle farkını hesapla\n",
    "            window = image[y:y+h, x:x+w]\n",
    "            score = np.sum((window - template)**2)  # Öklidyen mesafe\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_match = (x, y, w, h)\n",
    "    \n",
    "    return best_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbcea4f-d4ca-403c-a2b7-6830cb3858af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_face_box(image, face_region):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    if face_region:\n",
    "        x, y, w, h = face_region\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b681cac-d9b5-490a-9f44-6f1118c49e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def template_matching_with_filter(image, template, step_size=10, scale_factors=[1.0, 0.9, 1.1], threshold=5e5, distance_threshold=30):\n",
    "    best_matches = []\n",
    "    img_h, img_w = image.shape\n",
    "    \n",
    "    for scale in scale_factors:\n",
    "        scaled_template = cv2.resize(template, (int(template.shape[1] * scale), int(template.shape[0] * scale)))\n",
    "        h, w = scaled_template.shape\n",
    "        \n",
    "        for y in range(0, img_h - h, step_size):\n",
    "            for x in range(0, img_w - w, step_size):\n",
    "                window = image[y:y+h, x:x+w]\n",
    "                score = np.sum((window - scaled_template)**2)\n",
    "                \n",
    "                if score < threshold:\n",
    "                    best_matches.append((x, y, w, h, score))\n",
    "    \n",
    "    # Skorlara göre sırala ve belirli bir mesafede olanları birleştir\n",
    "    best_matches = sorted(best_matches, key=lambda x: x[4])\n",
    "    filtered_matches = merge_close_matches(best_matches, distance_threshold)\n",
    "    \n",
    "    return filtered_matches[:7]\n",
    "\n",
    "def merge_close_matches(matches, distance_threshold=30):\n",
    "    merged_matches = []\n",
    "    for (x, y, w, h, score) in matches:\n",
    "        merged = False\n",
    "        for i, (mx, my, mw, mh, mscore) in enumerate(merged_matches):\n",
    "            if abs(mx - x) < distance_threshold and abs(my - y) < distance_threshold:\n",
    "                merged = True\n",
    "                break\n",
    "        if not merged:\n",
    "            merged_matches.append((x, y, w, h, score))\n",
    "    return merged_matches\n",
    "\n",
    "# Görselleştirme fonksiyonu\n",
    "def draw_face_boxes(image, face_regions):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for (x, y, w, h, score) in face_regions:\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "import cv2\n",
    "\n",
    "def apply_threshold(image, threshold_value=100):\n",
    "    _, thresholded_image = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    return thresholded_image\n",
    "\n",
    "\n",
    "\n",
    "# Kenar görüntüsüne threshold uygulayın\n",
    "edge_image = apply_threshold(edge_dedection_grayscale_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e53f9-7bf8-4a0f-97b5-e4d0fac456e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = template_matching_with_filter(edge_image, edge_dedection_eye_scale)\n",
    "draw_face_boxes(edge_dedection_grayscale_frame, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a883d7c-65e4-461d-8f55-1e4ee2a66118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f29c0-2be6-46e5-8ec3-de96505d9423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c75f0-3623-42a5-82ad-b334d2342f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42f55e-1f09-4cfe-8bd5-f024c6c8adf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06c14f-3de1-445a-bf9f-84660d3a96a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaab04c-5e75-40bc-87cb-e494bcf7a022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7e0ef-4cdf-424c-a785-644405d09bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc5058-07b7-42c4-a318-37558be2112f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8ad0a-4a2e-43ce-8988-733d8be111ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d13bd-e705-415c-a7da-6b086e598c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904088fd-bb15-401d-a603-ceb4f51aa0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61951f8f-bd32-4852-94d1-bc70726ba8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4469c6-52f5-4d27-a2f3-55031e394dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921ef2b-3fed-4824-a4f7-a78ab8d82f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2c86f-b15b-4f46-a16a-1402adbb5446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a1848-0558-425d-a96c-1b489e810ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edge_dedection_grayscale_frame_resize = edge_dedection_grayscale_frame[40:420, 180:430]\n",
    "\n",
    "plt.imshow(edge_dedection_grayscale_frame_resize)\n",
    "plt.title(\"edge_dedection_grayscale_frame\")\n",
    "plt.show()\n",
    "\n",
    "edge_dedection_grayscale_frame_resize = cv2.resize(edge_dedection_grayscale_frame_resize, (185, 265))\n",
    "\n",
    "plt.imshow(edge_dedection_grayscale_frame_resize)\n",
    "plt.title(\"edge_dedection_grayscale_frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847be62-f42e-44b0-ab18-437e8f54a839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40858088-f1de-4b94-b830-52bf649fdd08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8b78b-0294-4391-8340-f220c38e2618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98188f3b-c868-4d99-b45a-6a737c765a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879035c-d665-45ff-b60b-4c2419022b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f756c-11be-45d0-9fe6-5bcb463ba7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf20cb4-be2d-4e8c-a90e-e10f665145ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d1f23-ac00-4ff9-8971-c738e971add5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cdc6f-46c6-4bb8-aa18-229d93490d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefdc97-bb8e-42db-b6a3-4a620bddcd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8b050-6539-4a32-90bd-b8c424192666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378487eb-982c-4819-bbda-c68ac4aa25d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd53269-df23-4d1b-bfe2-9be1aaedbdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6843f79-b3df-4317-9fa4-18e6c4239951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab00cb9-ac3c-42bb-a5e8-ff61da68ed05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b33337-247d-4636-b5cd-623172c50b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b3397-4d5c-41a2-bc7f-572b39560d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fdc55-5209-4b44-aa04-c94fa223efa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbacd246-81b0-4cec-863a-58043d216e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf97e5-2e6d-45c9-87fe-4fb064547435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5c2e5-92e6-4606-baec-13d2efeb05e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230f0ec-63e8-4443-b48d-b81d03d9d21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff6888-d351-4206-890d-75ab1498c225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a965416-b657-40ed-a590-912fd266c32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f4732-388f-4033-bc37-5b1d13d391dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b54d2d-d734-4382-9cde-77a1dc78bc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32722a3c-b3d0-45ab-95a1-ba41005b149f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf887182-9e02-4090-a74c-86f68fc0c8d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "original_image = cv.imread('./test/youtube-43_jpg.rf.5806bace236e1162900bf79aeaf44f36.jpg', cv.IMREAD_COLOR)\n",
    "#image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "frame_red = original_image[:, :, 2]\n",
    "frame_green = original_image[:, :, 1]\n",
    "frame_blue = original_image[:, :, 0]\n",
    "original_image_rgb = np.dstack((frame_red, frame_green, frame_blue))\n",
    "\n",
    "plt.imshow(original_image_rgb)\n",
    "plt.title(\"Frame\")\n",
    "plt.show()\n",
    "\n",
    "#image = rgb_to_grayscale(image)\n",
    "original_image_rgb = original_image_rgb[10:275, 210:395]\n",
    "#original_image_rgb = cv2.resize(original_image_rgb, (64, 128))\n",
    "\n",
    "\n",
    "original_image_grayscale = rgb_to_grayscale(original_image_rgb)\n",
    "\n",
    "plt.imshow(original_image_grayscale)\n",
    "plt.title(\"Frame_grayscale\")\n",
    "plt.show()\n",
    "\n",
    "filtered_original_image = gaussian_filter(original_image_grayscale, kernel_size = 3, sigma = 5)\n",
    "\n",
    "plt.imshow(filtered_original_image)\n",
    "plt.title(\"filtered_grayscale_frame\")\n",
    "plt.show()\n",
    "\n",
    "edge_dedection_original_image = sobel_filter(filtered_original_image)\n",
    "\n",
    "plt.imshow(edge_dedection_original_image)\n",
    "plt.title(\"edge_dedection_grayscale_frame\")\n",
    "plt.show()\n",
    "\n",
    "#deneme = list([0, 0, original_image_rgb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2cbd4-2dfe-43d4-806e-fa1988f313d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0824b-2daa-42e7-8a74-852fdb6b1b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a15961-2bb1-4b4e-afce-505c6ba4a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1 = edge_dedection_grayscale_frame_resize.flatten()\n",
    "I2 = edge_dedection_original_image.flatten()\n",
    "\n",
    "I1_mean = np.mean(I1)\n",
    "I2_mean = np.mean(I2)\n",
    "\n",
    "numerator = np.sum((I1 - I1_mean) * (I2 - I2_mean))\n",
    "denominator = np.sqrt(np.sum((I1 - I1_mean) ** 2) * np.sum((I2 - I2_mean) ** 2))\n",
    "\n",
    "correlation = numerator / denominator\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d823f-93e4-4108-abf4-2e5734a20cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
